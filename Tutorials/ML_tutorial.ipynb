{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"id":"vDh5IKupnU-N","outputId":"b70a0634-f2e3-42e8-99ef-90e8b83982b1"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7f9c5135c950>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch\n","from torch.utils.data import DataLoader\n","import os\n","import time\n","from Common import NeuralNet, fit\n","torch.manual_seed(42)\n"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"uYeh8fLEnU-O"},"source":["## Multilevel Training for the Heat Equation\n","\n","Consider the parametric one-dimensional heat equation:\n","\n","$$\n","u_t(t, x, y) = ku_{xx}(t, x, y), \\quad x\\in [0,1], t\\in[0,T], y\\in[0,1]^d\n","$$\n","\n","with zero Dirichlet boundary conditions and parametrized initial condition\n","$$\n","u_0(x,y) = \\sum_{j=1}^d (2y_j -1 ) \\sin(2\\pi j x)\n","$$\n","The observable is the heat flux at (T,0):\n","$$\n","L(y) = -k\\frac{\\partial T}{\\partial x}|_{t=T,x=0}\n","$$\n","\n","The heat equation can be solved with a simple finite difference scheme given a mesh with grid sizes $\\Delta x$ and $\\Delta t$, and the heat flux computed from the resulting numerical approximation. \n","Let us define the approximate flux as $L^\\Delta$.\n","\n","We are interested in the input to the observable map:\n","$$\n","L: y \\mapsto L^\\Delta(y), \\quad y\\in[0,1]^d\n","$$\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"id":"OIc_NXawnU-P"},"outputs":[],"source":["def solve_heat_eq(x, y):\n","    T = 0.01\n","    ic = (2 * y[0] - 1) * np.sin(2 * np.pi * x) + \\\n","         (2 * y[1] - 1) * np.sin(4 * np.pi * x) + \\\n","         (2 * y[2] - 1) * np.sin(6 * np.pi * x) + \\\n","         (2 * y[3] - 1) * np.sin(8 * np.pi * x)\n","\n","    \n","    # Heat Diffusivity\n","    diff = 1\n","    # Grid spacing delta_x\n","    dx = x[1] - x[0]\n","    # Time step delta_t\n","    dt = 0.4 * dx ** 2 / diff\n","\n","    F = diff * dt / dx ** 2\n","    nt = int((T / dt))\n","    nx = x.shape[0]\n","\n","    u_old = ic\n","    u_new = np.zeros_like(ic)\n","\n","    for k in range(1, nt):\n","        for i in range(1, nx - 1):\n","            u_new[i] = u_old[i] + F * (u_old[i + 1] - 2 * u_old[i] + u_old[i - 1])\n","        u_new[0] = 0\n","        u_new[-1] = 0\n","        u_old[:] = u_new\n","\n","    # Compute the heat flux at x=0, t = T\n","    flux = -diff * (u_new[0] - u_new[1]) / dx\n","    return flux\n","\n"]},{"cell_type":"markdown","metadata":{"collapsed":true,"pycharm":{"name":"#%% md\n"},"id":"gX8va7ydnU-P"},"source":["Consider a hierarchy of meshes with grid size $\\Delta_\\ell =\\frac{\\Delta_0}{2^\\ell}$, $\\ell=0,...,L$, $\\Delta_0 = \\frac{1}{20}$ and express the observable $L^{\\Delta_L}(y)$ at the finest mesh resolution $\\Delta_L$ in terms of a telescopic sum:\n","\n","$$\n","L^{\\Delta_L}(y) = L^{\\Delta_0}(y) + \\sum_{\\ell=1}^L (L^{\\Delta_\\ell}(y) - L^{\\Delta_{\\ell-1}}(y))= L^{\\Delta_0}(y) + \\sum_{\\ell=1}^L D_\\ell(y)\n","$$ \n","with\n","\n","$$\n","D_\\ell (y) = L^{\\Delta_\\ell}(y) - L^{\\Delta_{\\ell-1}}(y),\\quad \\ell=1,...,L \n","$$\n","\n","denoted as details.\n","\n","**Idea multilevel training**: instead of approximating directly the map $y \\mapsto L^{\\Delta_L}(y)$ with neural network $L^{\\Delta_L, \\ast} \\approx L^{\\Delta_L}$ trained with a training set $S_L = \\{ (y_k, L^{\\Delta_L}_k),\\quad k=1,...,N_L\\}$, define the approximate model as:\n","\n","$$\n"," L^{\\Delta_L, \\ast}(y) = L^{\\Delta_0, \\ast}(y) + \\sum_{\\ell=1}^L D^\\ast_\\ell(y)\n","$$\n","\n","with\n","\n","$$\n","L^{\\Delta_0, \\ast}\\approx L^{\\Delta_0}, \\quad D^\\ast_\\ell \\approx D_\\ell ~~\\ell=1,...,L\n","$$\n","\n","being neural networks trained with training sets $S_0= \\{ (y_k, L^{\\Delta_0}_k), k=1,...,N_0\\}$, $S_\\ell= \\{ (y_k, D_{\\ell,k}), k=1,...,N_L\\}$ and\n","\n","$$\n","N_\\ell = N_L\\cdot 2^{L-\\ell}.\n","$$\n","\n","Observe that the k-th realization of the detail $D_{\\ell,k} $ has to be computed given the same realization of the input parameter $y_k$. \n"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"0Rs9-aPrnU-P"},"source":["**Generate $N_\\ell$, $\\ell=0,...,L$, realizations of the observable at different mesh resolution to assemble later on the training sets**"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"id":"n8qWVXTqnU-P","outputId":"6edef0dd-2815-452b-e786-edcdfe0bbe93"},"outputs":[{"name":"stdout","output_type":"stream","text":["###############################\n","Generating Training Sets\n","##############################################################\n","Generated  400  realizations of the observable on a spatial mesh with  21  grid points. Time per sample:  0.0002\n","##############################################################\n","Generated  200  realizations of the observable on a spatial mesh with  41  grid points. Time per sample:  0.0017\n","##############################################################\n","Generated  100  realizations of the observable on a spatial mesh with  81  grid points. Time per sample:  0.0135\n","##############################################################\n","Generated  50  realizations of the observable on a spatial mesh with  161  grid points. Time per sample:  0.1069\n","Total time required to generate data:  7.115\n"]}],"source":["print(\"###############################\")\n","print(\"Generating Training Sets\")\n","np.random.seed(42)\n","L=3                                                # Finest resolution level L\n","l_values = np.array([L-3,L-2,L-1,L])               # List of all resolution levels l, from the finest (l=L=3) to the coarsest (l=0)\n","\n","ns_finest=50                                       # Number of training samples at the finest resolution level L\n","nx_coarsest = 20                                   # Number of grid points at the coarsest resolution level L\n","nx_values = nx_coarsest*2**l_values                # Number of grid points at the remaining resolution levels\n","nx_finest = nx_values[-1]\n","\n","ns_values = ns_finest*2**(l_values[-1] - l_values) # Number of training samples at the remaining resolution levels\n","\n","# Generate N_0 realizations of the parameters\n","y = np.random.random((ns_values[0], 4))\n","\n","datasets_meshes = []\n","total_time = 0\n","# Loop over the meshes and generate ns realizations of the observable at the mesh with nx grid points \n","for nx, ns in zip(nx_values, ns_values):\n","\n","    s = np.zeros((ns, y.shape[1] + 1))\n","\n","    print(\"##############################################################\")\n","   \n","    x_ = np.linspace(0, 1, nx + 1)\n","    start = time.time()\n","    for j in range(ns):\n","        f = solve_heat_eq(x_, y[j])\n","        s[j, :4] = y[j]\n","        s[j, -1] = f\n","    end = round((time.time() - start)/ns, 4)\n","    total_time = total_time + end*ns\n","    print(\"Generated \", ns,\" realizations of the observable on a spatial mesh with \", nx + 1, \" grid points. Time per sample: \", end)\n","\n","    datasets_meshes.append(s)\n","print(\"Total time required to generate data: \", total_time)"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"JMpUcKcRnU-Q"},"source":["**Generate training set $S_\\ell$ for learning the detail maps $y\\mapsto D_\\ell(y)$, $\\ell=1,...,L$**"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"id":"pa3wHrxLnU-Q","outputId":"a154fec6-ca76-4a22-90f5-8d03e81f99d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Variance of details at level l = 1 :  0.07059189551141742\n","Variance of details at level l = 2 :  0.0038554830215633256\n","Variance of details at level l = 3 :  0.00019470864320350647\n"]}],"source":["training_sets = list()\n","training_sets.append(datasets_meshes[0])\n","\n","# Obtain the details at different mesh resolutions \n","for l in range(1, len(datasets_meshes)):\n","    ns = datasets_meshes[l].shape[0]\n","    assert ((datasets_meshes[l][:ns, :y.shape[1]] == datasets_meshes[l - 1][:ns, :y.shape[1]]).all())\n","\n","    obs_diff = datasets_meshes[l][:ns, -1] - datasets_meshes[l - 1][:ns, -1]\n","    print(\"Variance of details at level l =\", l ,\": \",np.var(obs_diff))\n","    ts_detail_l = np.concatenate([datasets_meshes[l][:ns, :y.shape[1]], obs_diff.reshape(-1, 1)], 1)\n","    training_sets.append(ts_detail_l)"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"u4GDnQX8nU-Q"},"source":["**Train all the building models of the multilevel scheme**\n","$$\n","L^{\\Delta_0, \\ast}\\approx L^{\\Delta_0}, \\quad D^\\ast_\\ell \\approx D_\\ell, ~~\\ell=1,...,L\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"id":"qoqypQPtnU-Q","outputId":"f696b70d-bc73-4316-ab7b-2cb35fe3bebc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final Training loss:  3.265416307840496e-05\n","Final Training loss:  2.2737967810826376e-06\n","Final Training loss:  6.867440447422268e-07\n","Final Training loss:  3.5353078686739536e-08\n"]}],"source":["approximate_models = list()\n","\n","for i, current_ts in enumerate(training_sets):\n","    inputs = torch.from_numpy(current_ts[:, :y.shape[1]]).type(torch.float32)\n","    output = torch.from_numpy(current_ts[:, -1].reshape(-1, 1)).type(torch.float32)\n","    batch_size = inputs.shape[0]\n","    training_set = DataLoader(torch.utils.data.TensorDataset(inputs, output), batch_size=batch_size, shuffle=True)\n","\n","    model = NeuralNet(input_dimension=inputs.shape[1], \n","                      output_dimension=output.shape[1], \n","                      n_hidden_layers=4, \n","                      neurons=20,\n","                      regularization_param=0.0, \n","                      regularization_exp=2, \n","                      retrain_seed=128)\n","    \n","\n","    optimizer_ = optim.LBFGS(model.parameters(), lr=0.1, max_iter=1, max_eval=50000, tolerance_change=1.0 * np.finfo(float).eps)\n","\n","    n_epochs = 500\n","    history = fit(model, training_set, n_epochs, optimizer_, p=2, verbose=False)\n","    print(\"Final Training loss: \", history[-1])\n","\n","\n","    approximate_models.append(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"id":"MDhnIZvznU-Q"},"outputs":[],"source":["def predcit_with_ml(list_models, inputs_):\n","    output_ = torch.zeros((inputs_.shape[0], 1))\n","    for i in range(len(list_models)):\n","        output_ = output_ + list_models[i](inputs_)\n","    return output_\n"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"vNjQLuVwnU-Q"},"source":["**Generate $N_{sl}$ realizations of the observable at the finest mesh resolution to equate the total cost required by the multilevel scheme**"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"id":"lJy9srKKnU-Q","outputId":"70a728c2-aca9-475b-8806-3b80cc9007f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated  67  on the finest mesh. Total time:  7.1806230545043945\n"]}],"source":["training_data_single_level = list()\n","start = time.time()\n","current_elapsed_time = 0\n","x_ = np.linspace(0, 1, nx_finest)\n","j = 0\n","while current_elapsed_time < total_time:\n","    f = solve_heat_eq(x_, y[j])\n","    sample = np.concatenate([y[j], np.array(f).reshape(1,)]).reshape(1,-1)\n","    training_data_single_level.append(sample)\n","    current_elapsed_time = time.time() - start\n","    j=j+1\n","    \n","print(\"Generated \", len(training_data_single_level), \" on the finest mesh. Total time: \", current_elapsed_time)\n","training_data_single_level = np.concatenate(training_data_single_level)"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"BD2dcn6rnU-Q"},"source":["**Train the corresponding single-level model by using $N_{sl}$ realization of the observable at the finest mesh resolution**"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"id":"_DFejdo_nU-Q","outputId":"21176588-7921-46c0-f6dd-0c7a3240005d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final Training loss:  1.1044460734410677e-05\n"]}],"source":["inputs = torch.from_numpy(training_data_single_level[:, :y.shape[1]]).type(torch.float32)\n","output = torch.from_numpy(training_data_single_level[:, -1].reshape(-1, 1)).type(torch.float32)\n","batch_size = inputs.shape[0]\n","training_set = DataLoader(torch.utils.data.TensorDataset(inputs, output), batch_size=batch_size, shuffle=True)\n","\n","model_finest = NeuralNet(input_dimension=inputs.shape[1], \n","                         output_dimension=output.shape[1], \n","                         n_hidden_layers=4, \n","                         neurons=20, \n","                         regularization_param=0.0, \n","                         regularization_exp=2,\n","                         retrain_seed=128)\n","optimizer_ = optim.LBFGS(model_finest.parameters(), lr=0.1, max_iter=1, max_eval=50000, tolerance_change=1.0 * np.finfo(float).eps)\n","\n","n_epochs = 500\n","history = fit(model_finest, training_set, n_epochs, optimizer_, p=2, verbose=False)\n","print(\"Final Training loss: \", history[-1])\n"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"MKlK7PXBnU-Q"},"source":["**Generate test set (at finest mesh resolution) and assess models performance**"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"id":"2Li4ZGRanU-Q"},"outputs":[],"source":["def generate_test_set(n_samples, n_grid):\n","    np.random.seed(34)\n","    inputs_ = np.random.random((n_samples, 4))\n","    s_ = np.zeros((n_samples, inputs_.shape[1] + 1))\n","    x_ = np.linspace(0, 1, n_grid)\n","    for j in range(n_samples):\n","        s_[j, :4] = inputs_[j]\n","        s_[j, -1] = solve_heat_eq(x_, inputs_[j])\n","\n","    return s_\n","\n","test_set = generate_test_set(1024, nx_finest)"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"},"id":"nbcNY2fJnU-R","outputId":"09eb4f3f-ba7c-4e8e-8999-6b75acfc2199"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error Multilevel model:  0.010485476814210415\n","Error Singlelevel model:  0.020693715661764145\n"]}],"source":["test_inputs = torch.from_numpy(test_set[:, :4]).type(torch.float32)\n","test_output = torch.from_numpy(test_set[:, -1]).type(torch.float32).reshape(-1, )\n","\n","test_pred_ml = predcit_with_ml(approximate_models, test_inputs).reshape(-1, )\n","test_pred_finest = model_finest(test_inputs).reshape(-1, )\n","err_ml = (torch.mean((test_output - test_pred_ml) ** 2) / torch.mean(test_output ** 2)) ** 0.5\n","err_fin = (torch.mean((test_output - test_pred_finest) ** 2) / torch.mean(test_output ** 2)) ** 0.5\n","\n","print(\"Error Multilevel model: \", err_ml.item())\n","print(\"Error Singlelevel model: \", err_fin.item())"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}